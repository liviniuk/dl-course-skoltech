{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks for segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget https://www.dropbox.com/s/jy34yowcf85ydba/data.zip?dl=0 -O data.zip\n",
    "# ! unzip -q data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your next task is to train neural network to segment cells edges.\n",
    "\n",
    "Here is an example of input data with corresponding ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human HT29 colon-cancer cells\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.subplot(1,2,1)\n",
    "im = sp.misc.imread('BBBC018_v1_images-fixed/train/00735-actin.DIB.bmp')\n",
    "plt.imshow(im)\n",
    "plt.subplot(1,2,2)\n",
    "mask = sp.misc.imread('BBBC018_v1_outlines/train/00735-cells.png')\n",
    "plt.imshow(mask, 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time you aren't provided with any code snippets, just input data and target metric - intersection-over-union (IoU) (see implementation below).\n",
    "\n",
    "You should train neural network to predict mask of edge pixels (pixels in gt images with value greater than 0).\n",
    "\n",
    "Use everything you've learnt by now: \n",
    "* any architectures for semantic segmentation (encoder-decoder like or based on dilated convolutions)\n",
    "* data augmentation (you will need that since train set consists of just 41 images)\n",
    "* fine-tuning\n",
    "\n",
    "You're not allowed to do only one thing: to train you network on test set.\n",
    "\n",
    "Your final solution will consist of an ipython notebook with code (for final network training + any experiments with data) and an archive with png images with network predictions for test images (one-channel images, 0 - for non-edge pixels, any non-zero value for edge pixels).\n",
    "\n",
    "Forestalling questions about baseline... well, let's say that a good network should be able to segment images with iou >= 0.29. This is not a strict criterion of full points solution, but try to obtain better numbers.\n",
    "\n",
    "Practical notes:\n",
    "* There is a hard data class imbalance in dataset, so the network output will be biased toward \"zero\" class. You can either tune the minimal probability threshold for \"edge\" class, or add class weights to increase the cost of edge pixels in optimized loss.\n",
    "* Dataset is small so actively use data augmentation: rotations, flip, random contrast and brightness\n",
    "* Better spend time on experiments with neural network than on postprocessing tricks (i.e test set augmentation).\n",
    "* Keep in mind that network architecture defines receptive field of pixel. If the size of network input is smaller than receptive field of output pixel, than probably you can throw some layers without loss of quality. It is ok to modify \"of-the-shelf\" architectures. \n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iou(prediction, ground_truth):\n",
    "    n_images = len(prediction)\n",
    "    intersection, union = 0, 0\n",
    "    for i in range(n_images):\n",
    "        intersection += np.logical_and(prediction[i] > 0, ground_truth[i] > 0).astype(np.float32).sum() \n",
    "        union += np.logical_or(prediction[i] > 0, ground_truth[i] > 0).astype(np.float32).sum()\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used UNet with some layers pretrained (from the pretrained VGG13_bn) and two loss functions: Jaccard and BinaryCrossEntropyWithLogitsLoss (with pos_weight of 10-25). Both ways best achieved model had validation IoU > 0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms as T, models as M\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import os, glob, time, copy, random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancerCellDataset(Dataset):\n",
    "    def __init__(self, image_path, mask_path, image_transform=None, mask_transform=None):\n",
    "        super(CancerCellDataset, self).__init__()\n",
    "        \n",
    "        # Get sorted image/mask paths.\n",
    "        images = glob.glob(os.path.join(image_path, '*.bmp'))\n",
    "        masks = glob.glob(os.path.join(mask_path, '*.png'))\n",
    "        \n",
    "        # Sort filenames to \n",
    "        images.sort()\n",
    "        masks.sort()\n",
    "        \n",
    "        self.data = list(zip(images, masks))\n",
    "        \n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, mask_path = self.data[idx]\n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "        mask = Image.open(mask_path)\n",
    "        \n",
    "        # \"Synchronize\" transformation of images and masks using same random seed.\n",
    "        seed = np.random.randint(2147483647)\n",
    "        if self.image_transform is not None:\n",
    "            random.seed(seed)\n",
    "            image = self.image_transform(image)\n",
    "        if self.mask_transform is not None:\n",
    "            random.seed(seed)\n",
    "            mask = self.mask_transform(mask)\n",
    "        \n",
    "        mask = (mask > 0).float()\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Some code parts may be stylized as in, or be directly from https://pytorch.org/tutorials/index.html\n",
    "\n",
    "image_dir = './BBBC018_v1_images-fixed/'\n",
    "mask_dir = './BBBC018_v1_outlines/'\n",
    "\n",
    "stages = ['train', 'val']\n",
    "\n",
    "image_transforms = {\n",
    "    'train': T.Compose([T.RandomHorizontalFlip(),\n",
    "                        T.RandomAffine(180, (.4, .4), (.8, 1.2), 30, Image.BILINEAR),\n",
    "                        T.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "                        T.ToTensor()]),\n",
    "    'val'  : T.ToTensor()}\n",
    "mask_transforms = {\n",
    "    'train': T.Compose([T.RandomHorizontalFlip(),\n",
    "                        T.RandomAffine(180, (.2, .2), (.8, 1.2), 20, Image.BILINEAR),\n",
    "                        T.ToTensor()]),\n",
    "    'val'  : T.ToTensor()}\n",
    "\n",
    "\n",
    "datasets = {stage: CancerCellDataset(os.path.join(image_dir, stage),\n",
    "                                     os.path.join(mask_dir, stage),\n",
    "                                     image_transform=image_transforms[stage],\n",
    "                                     mask_transform=mask_transforms[stage])\n",
    "            for stage in stages}\n",
    "\n",
    "batch_sizes = {'train': 3,\n",
    "               'val': 7}\n",
    "\n",
    "dataloaders = {stage: torch.utils.data.DataLoader(datasets[stage],\n",
    "                                                  batch_size=batch_sizes[stage],\n",
    "                                                  shuffle=True,\n",
    "                                                  num_workers=32,\n",
    "                                                  drop_last=False)\n",
    "               for stage in stages}\n",
    "\n",
    "dataset_sizes = {stage: len(datasets[stage]) for stage in stages}\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-net from the paper https://arxiv.org/pdf/1505.04597.pdf\n",
    "# Implementated using some ideas from \n",
    "# https://github.com/milesial/Pytorch-UNet and https://github.com/ternaus/TernausNet\n",
    "\n",
    "class DoubleConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv2d, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Down, self).__init__()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.double_conv = DoubleConv2d(in_channels, in_channels*2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.max_pool(x)\n",
    "        x = self.double_conv(x)\n",
    "        return x\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Up, self).__init__()\n",
    "        self.pad = nn.ZeroPad2d((0,1,0,1))\n",
    "        self.conv_up = nn.Conv2d(in_channels, in_channels//2, kernel_size=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.double_conv = DoubleConv2d(in_channels, in_channels//2)\n",
    "    \n",
    "    def forward(self, x, copy):\n",
    "        # Up-Convolution\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        x = self.pad(x)\n",
    "        x = self.relu(self.conv_up(x))\n",
    "\n",
    "        # Concatenate\n",
    "        x = torch.cat([copy, x], dim=1)\n",
    "        \n",
    "        # Two Conv layers\n",
    "        x = self.double_conv(x)\n",
    "        return x\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, pretrained_encoder=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inp = DoubleConv2d(3, 64)\n",
    "        self.down1 = Down(64)\n",
    "        self.down2 = Down(128)\n",
    "        self.down3 = Down(256)\n",
    "        self.down4 = Down(512)\n",
    "        self.up1 = Up(1024)\n",
    "        self.up2 = Up(512)\n",
    "        self.up3 = Up(256)\n",
    "        self.up4 = Up(128)\n",
    "        self.out = nn.Conv2d(64, 1, kernel_size=1)\n",
    "        \n",
    "        if pretrained_encoder == True:\n",
    "            # Load some layers from pretrained vgg13_bn.\n",
    "            encoder = M.vgg13_bn(pretrained=True).features\n",
    "            \n",
    "            blocks = [self.inp, self.down1, self.down2, self.down3]\n",
    "            first_indexes = [0, 7, 14, 21]\n",
    "            for i, block in zip(first_indexes, blocks): \n",
    "                block.conv1 = encoder[i]\n",
    "                block.bn1 = encoder[i+1]\n",
    "                block.conv2 = encoder[i+2]\n",
    "                block.bn2 = encoder[i+3]\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x1 = self.inp(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "loss_history = {'train': [], 'val': []}\n",
    "best_acc = 0.0\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=10,  acc=0.0):\n",
    "    since = time.time()\n",
    "\n",
    "    global best_model\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    global best_acc\n",
    "    best_acc = acc\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            since_epoch = time.time()\n",
    "        \n",
    "            # Set the model mode\n",
    "            model.train() if phase == 'train' else model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            predictions = []\n",
    "            ground_truths = []\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, masks in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                masks = masks.to(device)\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    if criterion.__name__ == 'jaccard_loss':\n",
    "                        loss = criterion(masks.long(), outputs)\n",
    "                    else:\n",
    "                        loss = criterion(outputs.view(-1), masks.view(-1))\n",
    "    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # statistics\n",
    "                batch_size = inputs.size(0)\n",
    "                running_loss += loss.item() * batch_size\n",
    "                # Store masks to calculate for the whole epoch\n",
    "                predicted_mask = (outputs.detach() >= 0).cpu().numpy()\n",
    "                masks = masks.cpu().numpy()\n",
    "                predictions.append(predicted_mask)\n",
    "                ground_truths.append(masks)\n",
    "            \n",
    "            # Verbose\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            predictions = np.concatenate(predictions)\n",
    "            ground_truths = np.concatenate(ground_truths)\n",
    "            epoch_iou = calc_iou(predictions, ground_truths)\n",
    "            print('{} Loss: {:.4f} IoU: {:.4f} Time: {:.1f} sec'.format(\n",
    "                phase, epoch_loss, epoch_iou, time.time() - since_epoch))\n",
    "            \n",
    "            loss_history[phase].append(epoch_loss)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "                if epoch_iou > best_acc:\n",
    "                    best_acc = epoch_iou\n",
    "                    best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val IoU: {:4f}'.format(best_acc))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskshow(i=0):\n",
    "    \"\"\"Visualize predicted mask probabilities, predicted mask, \n",
    "    and ground truth mask for a validation smaple.\n",
    "    Args:\n",
    "        i: number of validation sample.\n",
    "    \"\"\"\n",
    "    inp, mask = datasets['val'][i]\n",
    "    out = net(inp.to(device)[None,...])\n",
    "\n",
    "    mask_pred = out[0,0].detach().sigmoid().cpu().numpy()\n",
    "    mask = mask[0].cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(mask_pred, 'gray', vmax=1, vmin=0)\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(mask_pred.round(), 'gray', vmax=1, vmin=0)\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(mask, 'gray', vmax=1, vmin=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccard Loss - code from https://github.com/kevinzakka/pytorch-goodies/blob/master/losses.py\n",
    "# From the paper - https://www.cs.toronto.edu/~urtasun/publications/mattyus_etal_iccv17.pdf\n",
    "def jaccard_loss(true, logits, eps=1e-7):\n",
    "    \"\"\"Computes the Jaccard loss, a.k.a the IoU loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the jaccard loss so we\n",
    "    return the negated jaccard loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, H, W] or [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        jacc_loss: the Jaccard loss.\n",
    "    \"\"\"\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        probas = F.softmax(probas, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type())\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "    union = cardinality - intersection\n",
    "    jacc_loss = (intersection / (union + eps)).mean()\n",
    "    return (1 - jacc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet(pretrained_encoder=True)\n",
    "net = net.to(device)\n",
    "\n",
    "# pos to neg in the train dataset is .961 : .039\n",
    "# criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(.961 / .039, dtype=torch.float32, device=device))\n",
    "criterion = jaccard_loss\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=.01, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Network output before training\n",
    "maskshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = train_model(net, criterion, optimizer, scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Network output after training\n",
    "maskshow(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(np.arange(1,1+len(loss_history['train'])), loss_history['train'], label='train')\n",
    "plt.plot(np.arange(1,1+len(loss_history['val'])), loss_history['val'], label='val')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.ylim(.37, .45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the network\n",
    "# torch.save(net, 'unet.pth.tar')\n",
    "# torch.save(net.state_dict(), 'unet_dict.pth.tar')\n",
    "# loss = np.concatenate((np.array(loss_history['train'])[:, None], np.array(loss_history['val'])[:, None]), axis=1)\n",
    "# np.savetxt('unet_loss.txt', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = UNet(pretrained_encoder=False)\n",
    "\n",
    "# # load the model\n",
    "# net.load_state_dict(torch.load('unet_dict.pth.tar'))\n",
    "# net = net.to(device)\n",
    "\n",
    "# # load the loss history\n",
    "# loss_history_np = np.loadtxt('unet_loss.txt')\n",
    "# loss_history = {'train': list(loss_history_np[:,0]), 'val': list(loss_history_np[:,1])}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
